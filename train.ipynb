{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# set the configuration\n",
    "import configparser\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "\n",
    "from models import UNet\n",
    "from models.deeplab import get_deeplab\n",
    "\n",
    "\n",
    "import seg_data\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomImageDataset(Dataset):\n",
    "#     def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "#         self.img_labels = pd.read_csv(annotations_file)\n",
    "#         self.img_dir = img_dir\n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.img_labels)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "#         image = read_image(img_path)\n",
    "#         label = self.img_labels.iloc[idx, 1]\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         if self.target_transform:\n",
    "#             label = self.target_transform(label)\n",
    "#         return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dice coefficient\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon: float = 1e-6):\n",
    "    # Average of Dice coefficient for all batches, or for a single mask\n",
    "    assert input.size() == target.size()\n",
    "    assert input.dim() == 3 or not reduce_batch_first\n",
    "\n",
    "    sum_dim = (-1, -2) if input.dim() == 2 or not reduce_batch_first else (-1, -2, -3)\n",
    "\n",
    "    inter = 2 * (input * target).sum(dim=sum_dim)\n",
    "    sets_sum = input.sum(dim=sum_dim) + target.sum(dim=sum_dim)\n",
    "    sets_sum = torch.where(sets_sum == 0, inter, sets_sum)\n",
    "\n",
    "    dice = (inter + epsilon) / (sets_sum + epsilon)\n",
    "    return dice.mean()\n",
    "\n",
    "\n",
    "def multiclass_dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon: float = 1e-6):\n",
    "    # Average of Dice coefficient for all classes\n",
    "    return dice_coeff(input.flatten(0, 1), target.flatten(0, 1), reduce_batch_first, epsilon)\n",
    "\n",
    "\n",
    "def dice_loss(input: Tensor, target: Tensor, multiclass: bool = False):\n",
    "    # Dice loss (objective to minimize) between 0 and 1\n",
    "    fn = multiclass_dice_coeff if multiclass else dice_coeff\n",
    "    return 1 - fn(input, target, reduce_batch_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,model_name, dataloader, device, amp = True):\n",
    "    \"\"\"Evaluate the validation set\n",
    "    \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    num_val_batches = len(dataloader)\n",
    "    dice_score = 0\n",
    "\n",
    "    # iterate over the validation set\n",
    "    with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
    "        for batch in dataloader:\n",
    "            images, mask_true = batch[0], batch[1]\n",
    "\n",
    "            # move images and labels to correct device and type\n",
    "            images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "            mask_true = mask_true.to(device=device, dtype=torch.float32)\n",
    "\n",
    "            # predict the mask\n",
    "            mask_pred = model(images)\n",
    "\n",
    "            if model_name==\"deeplab\":\n",
    "                mask_pred = mask_pred['out']\n",
    "\n",
    "            if model.n_classes == 1:\n",
    "                assert mask_true.min() >= 0 and mask_true.max() <= 1, 'True mask indices should be in [0, 1]'\n",
    "                mask_pred = (F.sigmoid(mask_pred) > 0.5).float()\n",
    "                # compute the Dice score\n",
    "                dice_score += dice_coeff(mask_pred, mask_true, reduce_batch_first=False)\n",
    "            else:\n",
    "                assert mask_true.min() >= 0 and mask_true.max() < model.n_classes, 'True mask indices should be in [0, n_classes['\n",
    "                # convert to one-hot format\n",
    "                mask_true = F.one_hot(mask_true.argmax(dim=1).to(torch.long), model.n_classes).permute(0, 3, 1, 2).float()\n",
    "                mask_pred = F.one_hot(mask_pred.argmax(dim=1), model.n_classes).permute(0, 3, 1, 2).float()\n",
    "                # compute the Dice score, ignoring background\n",
    "                dice_score += multiclass_dice_coeff(mask_pred[:, 1:], mask_true[:, 1:], reduce_batch_first=False)\n",
    "\n",
    "    model.train()\n",
    "    return dice_score / max(num_val_batches, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIR\n",
      "('image_dir', './data/test_10/img')\n",
      "('mask_dir', './data/test_10/mask_pl/')\n",
      "('checkpoint_path', './checkpoint/')\n",
      "PARAMS\n",
      "('model', 'deeplab')\n",
      "('scale', '10')\n",
      "('n_classes', '2')\n",
      "('epochs', '15')\n",
      "('learning_rate', '0.001')\n",
      "('val_percent', '20')\n",
      "('batch_size', '4')\n",
      "UNET\n",
      "('bilinear', 'TRUE')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "## Read the config\n",
    "def read_ini(file_path):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(file_path)\n",
    "    return config\n",
    "\n",
    " \n",
    "config = read_ini(\"./train_config.ini\")\n",
    "\n",
    "for section in config.sections():\n",
    "    print(section)\n",
    "    for key in config[section]:\n",
    "        print((key, config[section][key]))\n",
    "\n",
    "\n",
    "img_path = config[\"DIR\"][\"image_dir\"]\n",
    "mask_path =config[\"DIR\"][\"mask_dir\"]\n",
    "checkpoint_path = config[\"DIR\"][\"checkpoint_path\"]\n",
    "\n",
    "model_name = config[\"PARAMS\"]['model']\n",
    "scale = int(config[\"PARAMS\"][\"scale\"])\n",
    "\n",
    "learning_rate = float(config[\"PARAMS\"]['learning_rate'])\n",
    "batch_size = int(config[\"PARAMS\"]['batch_size'])\n",
    "val_percent = int(config[\"PARAMS\"]['val_percent'])\n",
    "\n",
    "# number of classes\n",
    "n_classes = int(config[\"PARAMS\"].get('n_classes',False))\n",
    "# Class weight, if not specified, assign None\n",
    "class_weights = config[\"PARAMS\"].get('class_weights',False)\n",
    "if class_weights:\n",
    "    \n",
    "    class_weights = eval(class_weights)\n",
    "    assert len(class_weights) == n_classes, \"The length of class weights: {} should equal to the number of classes: {}\".format(len(class_weights),n_classes)\n",
    "    class_weights_tensor = torch.tensor(class_weights)\n",
    "    class_weights = True\n",
    "\n",
    "epochs = int(config[\"PARAMS\"]['epochs'])\n",
    "\n",
    "\n",
    "\n",
    "# n_classes = config\n",
    "\n",
    "# config.get(\"UNET\")\n",
    "if model_name == \"unet\" and \"UNET\" in config:\n",
    "    bilinear = config[\"UNET\"][\"bilinear\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info:\n",
      "        Image folder: ./data/test_10/img\n",
      "        input image scale: 10\n",
      "        Mask folder: ./data/test_10/mask_pl/\n",
      "        Dataset length: 10\n",
      "        Validation set percentage: 20\n",
      "        Batch size: 4\n",
      "    \n",
      "System info:\n",
      "        Using device: cuda\n",
      "        CPU cores: 16\n",
      "        GPU count: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read and init datasets\n",
    "dataset = seg_data.segDataset(img_path = img_path, \n",
    "    mask_path = mask_path,\n",
    "    scale=20)\n",
    "\n",
    "# Split and create dataloader\n",
    "l=dataset.__len__()\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-int(np.ceil(l*val_percent/100))])\n",
    "dataset_val = torch.utils.data.Subset(dataset, indices[int(-np.ceil(l*val_percent/100)):])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                        shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size,\n",
    "                                        shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "print(f'''Dataset info:\n",
    "        Image folder: {img_path}\n",
    "        input image scale: {scale}\n",
    "        Mask folder: {mask_path}\n",
    "        Dataset length: {l}\n",
    "        Validation set percentage: {val_percent}\n",
    "        Batch size: {batch_size}\n",
    "    ''')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'''System info:\n",
    "        Using device: {device}\n",
    "        CPU cores: {os.cpu_count()}\n",
    "        GPU count: {torch.cuda.device_count()}\n",
    "'''\n",
    ")\n",
    "\n",
    "\n",
    "# init model and device\n",
    "\n",
    "\n",
    "\n",
    "### Unet ###\n",
    "if model_name =='unet':\n",
    "    model = UNet(n_channels=3, n_classes=n_classes, bilinear=bilinear)\n",
    "elif model_name ==\"deeplab\":\n",
    "    model = get_deeplab(n_classes)\n",
    "    \n",
    "# switch NCHW to NHWC\n",
    "model = model.to(memory_format=torch.channels_last)\n",
    "model.to(device=device)\n",
    "\n",
    "# Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "optimizer = optim.RMSprop(model.parameters(),\n",
    "                            lr=learning_rate, foreach=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)  # goal: maximize Dice score\n",
    "# grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "\n",
    "# Loss function\n",
    "if class_weights:\n",
    "    print(\"Using class weight in loss: {}\".format(class_weights_tensor))\n",
    "    class_weights_tensor = class_weights_tensor.to(device=device)\n",
    "    criterion = nn.CrossEntropyLoss(weight= class_weights_tensor) if n_classes > 1 else nn.BCEWithLogitsLoss()\n",
    "# Loss function with class weight\n",
    "else:\n",
    "    print(\"No class weight in loss\")\n",
    "    criterion = nn.CrossEntropyLoss() if n_classes > 1 else nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "scaler=None\n",
    "\n",
    "# Learning rate warm up\n",
    "warmup_factor = 1.0 / 1000\n",
    "warmup_iters = min(1000, len(train_loader) - 1)\n",
    "warm_up_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
    ")\n",
    "\n",
    "print(\n",
    "    f'''Model info:\n",
    "        Model name: {model_name}\n",
    "        \n",
    "        Output channels: {n_classes}\n",
    "        Epochs: {epochs}\n",
    "        Learning Rate: {learning_rate}\n",
    "        \n",
    "''')\n",
    " \n",
    "#{\"Bilinear\" if model.bilinear else \"Transposed conv\"} upscaling\n",
    "\n",
    "\n",
    "\n",
    "# if args.load:\n",
    "#     state_dict = torch.load(args.load, map_location=device)\n",
    "#     del state_dict['mask_values']\n",
    "#     model.load_state_dict(state_dict)\n",
    "#     logging.info(f'Model loaded from {args.load}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\csyic\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\csyic\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 60991319, trainable: 16125954\n",
      "No class weight in loss\n",
      "Model info:\n",
      "        Model name: deeplab\n",
      "        \n",
      "        Output channels: 2\n",
      "        Epochs: 15\n",
      "        Learning Rate: 0.001\n",
      "        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# init model and device\n",
    "\n",
    "\n",
    "\n",
    "### Unet ###\n",
    "if model_name =='unet':\n",
    "    model = UNet(n_channels=3, n_classes=n_classes, bilinear=bilinear)\n",
    "elif model_name ==\"deeplab\":\n",
    "    model = get_deeplab(n_classes)\n",
    "    \n",
    "# switch NCHW to NHWC\n",
    "model = model.to(memory_format=torch.channels_last)\n",
    "model.to(device=device)\n",
    "\n",
    "# Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "optimizer = optim.RMSprop(model.parameters(),\n",
    "                            lr=learning_rate, foreach=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)  # goal: maximize Dice score\n",
    "# grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "\n",
    "# Loss function\n",
    "if class_weights:\n",
    "    print(\"Using class weight in loss: {}\".format(class_weights_tensor))\n",
    "    class_weights_tensor = class_weights_tensor.to(device=device)\n",
    "    criterion = nn.CrossEntropyLoss(weight= class_weights_tensor) if n_classes > 1 else nn.BCEWithLogitsLoss()\n",
    "# Loss function with class weight\n",
    "else:\n",
    "    print(\"No class weight in loss\")\n",
    "    criterion = nn.CrossEntropyLoss() if n_classes > 1 else nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "scaler=None\n",
    "\n",
    "# Learning rate warm up\n",
    "warmup_factor = 1.0 / 1000\n",
    "warmup_iters = min(1000, len(train_loader) - 1)\n",
    "warm_up_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
    ")\n",
    "\n",
    "print(\n",
    "    f'''Model info:\n",
    "        Model name: {model_name}\n",
    "        \n",
    "        Output channels: {n_classes}\n",
    "        Epochs: {epochs}\n",
    "        Learning Rate: {learning_rate}\n",
    "        \n",
    "''')\n",
    " \n",
    "#{\"Bilinear\" if model.bilinear else \"Transposed conv\"} upscaling\n",
    "\n",
    "\n",
    "\n",
    "# if args.load:\n",
    "#     state_dict = torch.load(args.load, map_location=device)\n",
    "#     del state_dict['mask_values']\n",
    "#     model.load_state_dict(state_dict)\n",
    "#     logging.info(f'Model loaded from {args.load}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1/15\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "Checkpoint 1 saved! in ./checkpoint/\n",
      "Training epoch: 2/15\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "Checkpoint 2 saved! in ./checkpoint/\n",
      "Training epoch: 3/15\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "Checkpoint 3 saved! in ./checkpoint/\n",
      "Training epoch: 4/15\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "Checkpoint 4 saved! in ./checkpoint/\n",
      "Training epoch: 5/15\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "Checkpoint 5 saved! in ./checkpoint/\n",
      "Training epoch: 6/15\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "Checkpoint 6 saved! in ./checkpoint/\n",
      "Training epoch: 7/15\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "Checkpoint 7 saved! in ./checkpoint/\n",
      "Training epoch: 8/15\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "Checkpoint 8 saved! in ./checkpoint/\n",
      "Training epoch: 9/15\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "Checkpoint 9 saved! in ./checkpoint/\n",
      "Training epoch: 10/15\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "Checkpoint 10 saved! in ./checkpoint/\n",
      "Training epoch: 11/15\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "Checkpoint 11 saved! in ./checkpoint/\n",
      "Training epoch: 12/15\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "Checkpoint 12 saved! in ./checkpoint/\n",
      "Training epoch: 13/15\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "Checkpoint 13 saved! in ./checkpoint/\n",
      "Training epoch: 14/15\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "Checkpoint 14 saved! in ./checkpoint/\n",
      "Training epoch: 15/15\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "torch.Size([4, 2, 164, 247]) torch.Size([4, 2, 164, 247])\n",
      "Checkpoint 15 saved! in ./checkpoint/\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "# 5. Begin training\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    print(\"Training epoch: {}/{}\".format(epoch,epochs))\n",
    "    for batch in train_loader:\n",
    "        images, true_masks = batch[0], batch[1]\n",
    "\n",
    "        # assert images.shape[1] == model.n_channels, \\\n",
    "        #     f'Network has been defined with {model.n_channels} input channels, ' \\\n",
    "        #     f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "        #     'the images are loaded correctly.'\n",
    "        \n",
    "\n",
    "        images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "        true_masks = true_masks.to(device=device, dtype=torch.float32)\n",
    "        \n",
    "\n",
    "        masks_pred = model(images)\n",
    "\n",
    "        if model_name ==\"deeplab\":\n",
    "            masks_pred = masks_pred['out']\n",
    "\n",
    "        print(true_masks.shape, masks_pred.shape)\n",
    "        if model.n_classes == 1:\n",
    "            loss = criterion(masks_pred.squeeze(1), true_masks.float())\n",
    "            loss += dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks.float(), multiclass=False)\n",
    "        else:\n",
    "            loss = criterion(masks_pred, true_masks)\n",
    "            loss += dice_loss(\n",
    "                F.softmax(masks_pred, dim=1).float(),\n",
    "                F.one_hot(true_masks.argmax(dim=1), model.n_classes).permute(0, 3, 1, 2).float(),\n",
    "                multiclass=True\n",
    "            )\n",
    "        writer.add_scalar('Loss/train', loss, epoch)\n",
    "        optimizer.zero_grad()\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch == 0:\n",
    "            warm_up_scheduler.step()\n",
    "        \n",
    "        # Update the global step and epoch loss\n",
    "        global_step += 1\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    \n",
    "    # Validation stage\n",
    "    val_score = evaluate(model,model_name, test_loader, device)\n",
    "    writer.add_scalar('Loss/Valid', loss, epoch)\n",
    "    scheduler.step(val_score)    \n",
    "\n",
    " \n",
    "    Path(checkpoint_path).mkdir(parents=True, exist_ok=True)\n",
    "    state_dict = model.state_dict()\n",
    "    # state_dict['mask_values'] = dataset.mask_values\n",
    "    torch.save(model, str(checkpoint_path + '/{}_checkpoint_epoch{}.pth'.format(model_name, epoch)))\n",
    "    print(f'Checkpoint {epoch} saved! in {checkpoint_path}')\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one_hot is only applicable to index tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[129], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m (F\u001b[39m.\u001b[39msoftmax(masks_pred, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfloat())\u001b[39m.\u001b[39mshape\n\u001b[1;32m----> 2\u001b[0m F\u001b[39m.\u001b[39;49mone_hot(true_masks, model\u001b[39m.\u001b[39;49mn_classes)\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mfloat(),\n",
      "\u001b[1;31mRuntimeError\u001b[0m: one_hot is only applicable to index tensor."
     ]
    }
   ],
   "source": [
    "(F.softmax(masks_pred, dim=1).float()).shape\n",
    "F.one_hot(true_masks, model.n_classes).permute(0, 3, 1, 2).float(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cv2.imshow(\"asd\",((true_masks.permute(0, 2,3,1))[0,...,1].cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3961"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((true_masks.permute(0, 2,3,1))[0,...,1].cpu().detach().numpy())==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.one_hot(true_masks.argmax(dim=1), model.n_classes).permute(0, 3, 1, 2).float()\n",
    "mask_pred = F.one_hot(masks_pred.argmax(dim=1), model.n_classes).permute(0, 3, 1, 2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eee9884d67d38226826b490dbaf1f28138930230f5f22b3ca12360cdbe3316e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
